<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><link rel="icon" type="image/svg+xml" href="/favicon.png"><meta name="viewport" content="width=device-width"><meta name="generator" content="Astro v3.0.11"><title></title><script async defer data-domain="rasulkireev.com" src="https://stats.rasulkireev.com/js/index.js"></script><link rel="stylesheet" href="https://maxst.icons8.com/vue-static/landings/line-awesome/line-awesome/1.3.0/css/line-awesome.min.css"><link rel="stylesheet" href="/_astro/_...slug_.d31f937d.css" /></head><body><footer class="flex flex-col max-w-4xl min-h-screen px-6 mx-auto leading-relaxed bg-white light-mode"><style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();;(()=>{var b=Object.defineProperty;var f=(a,s,i)=>s in a?b(a,s,{enumerable:!0,configurable:!0,writable:!0,value:i}):a[s]=i;var d=(a,s,i)=>(f(a,typeof s!="symbol"?s+"":s,i),i);var u;{let a={0:t=>m(t),1:t=>i(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(i(t)),5:t=>new Set(i(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t)},s=t=>{let[e,r]=t;return e in a?a[e](r):void 0},i=t=>t.map(s),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([e,r])=>[e,s(r)]));customElements.get("astro-island")||customElements.define("astro-island",(u=class extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var l;if(!this.hydrator||!this.isConnected)return;let e=(l=this.parentElement)==null?void 0:l.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let r=this.querySelectorAll("astro-slot"),c={},h=this.querySelectorAll("template[data-astro-template]");for(let n of h){let o=n.closest(this.tagName);o!=null&&o.isSameNode(this)&&(c[n.getAttribute("data-astro-template")||"default"]=n.innerHTML,n.remove())}for(let n of r){let o=n.closest(this.tagName);o!=null&&o.isSameNode(this)&&(c[n.getAttribute("name")||"default"]=n.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(n){let o=this.getAttribute("component-url")||"<unknown>",y=this.getAttribute("component-export");throw y&&(o+=` (export ${y})`),console.error(`[hydrate] Error parsing props for component ${o}`,this.getAttribute("props"),n),n}await this.hydrator(this)(this.Component,p,c,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){!this.hasAttribute("await-children")||this.firstChild?this.childrenConnectedCallback():new MutationObserver((e,r)=>{r.disconnect(),setTimeout(()=>this.childrenConnectedCallback(),0)}).observe(this,{childList:!0})}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}start(){let e=JSON.parse(this.getAttribute("opts")),r=this.getAttribute("client");if(Astro[r]===void 0){window.addEventListener(`astro:${r}`,()=>this.start(),{once:!0});return}Astro[r](async()=>{let c=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),c?import(c):()=>()=>{}]),l=this.getAttribute("component-export")||"default";if(!l.includes("."))this.Component=h[l];else{this.Component=h;for(let n of l.split("."))this.Component=this.Component[n]}return this.hydrator=p,this.hydrate},e,this)}attributeChangedCallback(){this.hydrate()}},d(u,"observedAttributes",["props"]),u))}})();</script><astro-island uid="lWppq" component-url="/_astro/Navbar.e6e8da12.js" component-export="default" renderer-url="/_astro/client.1070f979.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;Navbar&quot;,&quot;value&quot;:true}" await-children=""><nav class="z-50 bg-white"><div class="px-4 mx-auto max-w-7xl"><div class="flex justify-between h-20"><div class="flex"><div class="flex items-center flex-shrink-0"><a href="/"><img class="block w-auto h-8 lg:hidden" src="/src/assets/images/logo.png" alt="Rasul Kireev"></a><a href="/"><img class="hidden w-auto h-12 lg:block" src="/src/assets/images/logo.png" alt="Rasul Kireev"></a></div></div><div class="flex items-center"><div class="hidden sm:ml-6 sm:flex sm:space-x-8"><a href="/" class="inline-flex items-center px-1 pt-1 text-lg font-medium text-gray-500 hover:text-gray-700"> Home </a><a href="/about/" class="inline-flex items-center px-1 pt-1 text-lg font-medium text-gray-500 hover:text-gray-700"> About </a><a href="/projects/" class="inline-flex items-center px-1 pt-1 text-lg font-medium text-gray-500 hover:text-gray-700"> Projects </a><div class="relative inline-block text-left"><div><button type="button" class="inline-flex items-center px-1 pt-1 text-lg font-medium text-gray-500 hover:text-gray-700" id="options-menu" aria-haspopup="true" aria-expanded="true"> Writings <svg class="w-5 h-5 ml-2 -mr-1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true"><path fill-rule="evenodd" d="M5.293 7.293a1 1 0 011.414 0L10 10.586l3.293-3.293a1 1 0 111.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><div style="display:none;" class="absolute right-0 w-56 mt-2 origin-top-right bg-white rounded-md shadow-lg ring-1 ring-black ring-opacity-5"><div class="py-1" role="menu" aria-orientation="vertical" aria-labelledby="options-menu"><a href="/articles/" class="block px-4 py-2 text-lg text-gray-700 hover:bg-gray-100 hover:text-gray-900">Articles</a><a href="/tutorials/" class="block px-4 py-2 text-lg text-gray-700 hover:bg-gray-100 hover:text-gray-900">Tutorials</a><a href="/book-notes/" class="block px-4 py-2 text-lg text-gray-700 hover:bg-gray-100 hover:text-gray-900">Book Notes</a><a href="/newsletter/" class="block px-4 py-2 text-lg text-gray-700 hover:bg-gray-100 hover:text-gray-900">Newsletter</a><a href="/now/" class="block px-4 py-2 text-lg text-gray-700 hover:bg-gray-100 hover:text-gray-900">Now</a></div></div></div></div><div class="flex items-center -mr-2 sm:hidden"><button class="inline-flex items-center justify-center p-2 text-gray-400 rounded-md hover:text-gray-500 hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-indigo-500" aria-expanded="false"><span class="sr-only">Open main menu</span><svg class="block w-6 h-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg><svg class="hidden w-6 h-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg></button></div></div></div></div><div class="hidden"><div class="pt-2 pb-3 space-y-1"><a href="/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">Home</a><a href="/about/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">About</a><a href="/articles/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">Articles</a><a href="/book-notes/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">Book Notes</a><a href="/tutorials/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">Tutorials</a><a href="/newsletter/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">Newsletter</a><a href="/now/" class="block py-2 pl-3 pr-4 text-base font-medium text-gray-600 hover:text-gray-800 hover:bg-gray-50 hover:border-gray-300">Now</a></div></div></nav></astro-island><p class="mb-10 text-blue-700">
‚Üê <a href="/tutorials">back to tutorials</a></p><article class="mb-6 prose lg:prose-xl h-entry" itemscope itemtype="http://schema.org/Article"><h1>Analyzing FIFA 19 data (III). Machine Learning and Prediction</h1><h2 id="source-code">Source code</h2>
<p>The project source code is in <a href="https://github.com/rasulkireev/fifa19-data-analysis">this</a> Github repo. You can review the code in this post in 3.1-machine-learning-by-the-book.</p>
<p>##Overview
In this post, we go through the process of building a machine learning algorithm. I am not making it from scratch. Scikit-learn has done all the work for us. We need to think about the ‚Äúbusiness‚Äù logic and best practices of using this library.</p>
<p>Please note, this is part 3 of our project. Please follow the links to review <a href="https://rasulkireev.com/fifa-data-cleaning/">Part 1</a> and <a href="https://rasulkireev.com/fifa-data-exploration/">Part 2</a>, where we talked about Data Cleaning and Exploration, respectively.</p>
<h2 id="initial-importing">Initial Importing</h2>
<p>Let‚Äôs begin. First, we need to import the standard packages and a ‚Äúclean‚Äù dataset (from the previous post).</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">%</span><span style="color: #E1E4E8">matplotlib inline</span></span>
<span class="line"></span>
<span class="line"><span style="color: #6A737D"># Standard Libraries to import</span></span>
<span class="line"><span style="color: #F97583">import</span><span style="color: #E1E4E8"> pandas </span><span style="color: #F97583">as</span><span style="color: #E1E4E8"> pd</span></span>
<span class="line"><span style="color: #F97583">import</span><span style="color: #E1E4E8"> matplotlib.pyplot </span><span style="color: #F97583">as</span><span style="color: #E1E4E8"> plt</span></span>
<span class="line"><span style="color: #F97583">import</span><span style="color: #E1E4E8"> numpy </span><span style="color: #F97583">as</span><span style="color: #E1E4E8"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">dataset </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> pd.read_csv(</span><span style="color: #9ECBFF">'data/processed/clean_dataset.csv'</span><span style="color: #E1E4E8">, </span><span style="color: #FFAB70">index_col</span><span style="color: #F97583">=</span><span style="color: #79B8FF">0</span><span style="color: #E1E4E8">)</span></span></code></pre>
<p>This should get us going.</p>
<h2 id="creating-a-test-set">Creating a test set.</h2>
<p>Before we begin any further exploration or analysis, we need to create a test set and set it aside. After you have your data, the first thing you should do is to set aside some test data. This ensures a safe and unbiased process.</p>
<h3 id="categorizing-overall-skills-into-bins">Categorizing Overall Skills into bins.</h3>
<p>This step helps us get the correct proportions of data from each Overall skill bin when we are splitting the dataset.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #6A737D"># Create a column that categorizes Overall Skills level into bins.</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">custom_bins </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> [i </span><span style="color: #F97583">for</span><span style="color: #E1E4E8"> i </span><span style="color: #F97583">in</span><span style="color: #E1E4E8"> </span><span style="color: #79B8FF">range</span><span style="color: #E1E4E8">(</span><span style="color: #79B8FF">45</span><span style="color: #E1E4E8">,</span><span style="color: #79B8FF">100</span><span style="color: #E1E4E8">,</span><span style="color: #79B8FF">5</span><span style="color: #E1E4E8">)]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">dataset[</span><span style="color: #9ECBFF">'overall_bins'</span><span style="color: #E1E4E8">] </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> pd.cut(dataset[</span><span style="color: #9ECBFF">'overall'</span><span style="color: #E1E4E8">],</span></span>
<span class="line"><span style="color: #E1E4E8">                                </span><span style="color: #FFAB70">bins</span><span style="color: #F97583">=</span><span style="color: #E1E4E8">custom_bins,</span></span>
<span class="line"><span style="color: #E1E4E8">                                </span><span style="color: #FFAB70">labels</span><span style="color: #F97583">=</span><span style="color: #E1E4E8">[i </span><span style="color: #F97583">for</span><span style="color: #E1E4E8"> i </span><span style="color: #F97583">in</span><span style="color: #E1E4E8"> </span><span style="color: #79B8FF">range</span><span style="color: #E1E4E8">(</span><span style="color: #79B8FF">len</span><span style="color: #E1E4E8">(custom_bins)</span><span style="color: #F97583">-</span><span style="color: #79B8FF">1</span><span style="color: #E1E4E8">)])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">dataset[</span><span style="color: #9ECBFF">'overall_bins'</span><span style="color: #E1E4E8">].hist()</span></span></code></pre>
<p>If everything works correctly, you should get a histogram that shows an uneven distribution of players that belongs to each ‚Äúgroup.‚Äù</p>
<p><img src="https://i.imgur.com/9Ge8gfU.png" alt="Histogram"></p>
<p>Let‚Äôs now split the dataset into the test set and training set. Thanks to Scikit-learn, it is straightforward. We are using the train_test_split function.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.model_selection </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> train_test_split</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">strat_train_set, strat_test_set </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> train_test_split(</span></span>
<span class="line"><span style="color: #E1E4E8">    dataset, </span><span style="color: #FFAB70">test_size</span><span style="color: #F97583">=</span><span style="color: #79B8FF">0.2</span><span style="color: #E1E4E8">, </span><span style="color: #FFAB70">random_state</span><span style="color: #F97583">=</span><span style="color: #79B8FF">42</span><span style="color: #E1E4E8">, </span><span style="color: #FFAB70">stratify</span><span style="color: #F97583">=</span><span style="color: #E1E4E8">dataset[</span><span style="color: #9ECBFF">"overall_bins"</span><span style="color: #E1E4E8">])</span></span></code></pre>
<p>Here, we set the test size to 20%, which is the standard proportion to pick. If you have a large data set, with millions of rows, then you can choose a smaller percentage. The random state helps us replicate the result in the future. You can use any integer, but 42 is a geeky standard.</p>
<blockquote>
<p>I have procrastinated on this post for a long
Time. I think this is just because it seems like there is too much work ahead. I have this subconscious desire to make it perfect, just because all the data science related posts I read seem to be that way. No more. I am at the beginning of my career, and putting this out in the world is way more important than making it perfect. So I try to keep this short, sweet, and simple (the new S3). In the future, when I have more time and experience, you can certainly expect much more detail, depth, and sass in my posts. Now, let‚Äôs continue.</p>
</blockquote>
<p>If you want to see the distribution of data along with the bins, you can run the following code.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #79B8FF">print</span><span style="color: #E1E4E8">(strat_test_set[</span><span style="color: #9ECBFF">"overall_bins"</span><span style="color: #E1E4E8">].value_counts()</span><span style="color: #F97583">/</span><span style="color: #79B8FF">len</span><span style="color: #E1E4E8">(strat_test_set))</span></span>
<span class="line"><span style="color: #79B8FF">print</span><span style="color: #E1E4E8">(</span><span style="color: #79B8FF">len</span><span style="color: #E1E4E8">(strat_test_set.overall))</span></span></code></pre>
<p><img src="https://i.imgur.com/5npYGWp.png" alt="Testing Distribution"></p>
<h2 id="prepare-the-data-for-machine-learning-algorithm">Prepare the Data for Machine Learning Algorithm</h2>
<h3 id="separating-dependent-and-independent-variables">Separating dependent and independent variables</h3>
<p>The first thing we are going to do is to separate the dependent and independent variables. Since we are trying to predict the value of the player, it is going to be our dependent variable. Other columns are the independent variables. This is the code to achieve that separation:</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #E1E4E8">dataset </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> strat_train_set.drop(</span><span style="color: #9ECBFF">"value"</span><span style="color: #E1E4E8">, </span><span style="color: #FFAB70">axis</span><span style="color: #F97583">=</span><span style="color: #79B8FF">1</span><span style="color: #E1E4E8">)</span></span>
<span class="line"><span style="color: #E1E4E8">dataset_labels </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> strat_train_set[</span><span style="color: #9ECBFF">"value"</span><span style="color: #E1E4E8">].copy()</span></span></code></pre>
<h3 id="converting-categorical-variable-to-numerical">Converting categorical variable to numerical</h3>
<p>We are using Scikit-learn built-in method called OneHotEncoder. This is great and simple to use the feature.</p>
<p><em><strong>I have to give Scikit-learn dev team a huge shoutout, they are doing a great job overall.</strong></em></p>
<p>The only categorical variable that we have is ‚ÄòPosition.‚Äô I think it is useful to consider player positions because they need different skills and attribute to be better or worse and will, therefore, affect the overall value of the player.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #6A737D"># One hot Encoding</span></span>
<span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.preprocessing </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> OneHotEncoder</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">dataset_categorical </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> dataset[[</span><span style="color: #9ECBFF">'position'</span><span style="color: #E1E4E8">]]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">cat_encoder </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> OneHotEncoder()</span></span>
<span class="line"><span style="color: #E1E4E8">dataset_categorical_1hot </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> cat_encoder.fit_transform(dataset_categorical)</span></span></code></pre>
<h3 id="scaling-your-features">Scaling your features</h3>
<p>Scaling is important when it comes to Machine Learning. Having values that vary in the range can through your algorithm off. So keeping everything on the same scale is very important. One way to do this is Scikit Learn‚Äôs built-in method called StandardScaler. This method applies the <a href="https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)">Min-Max feature scaling</a>
, which essentially yields values from 0 to 1.</p>
<p>I use a Pipeline method to apply the scaling. This helps us automate the process in the future by creating a pipeline. This is how the code looks like:</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.pipeline </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> Pipeline</span></span>
<span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.preprocessing </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> StandardScaler</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">num_pipeline </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> Pipeline([</span></span>
<span class="line"><span style="color: #E1E4E8">        (</span><span style="color: #9ECBFF">'std_scaler'</span><span style="color: #E1E4E8">, StandardScaler()),</span></span>
<span class="line"><span style="color: #E1E4E8">    ])</span></span></code></pre>
<h3 id="creating-a-full-pipeline">Creating a Full Pipeline</h3>
<p>The final step in preparing the data is to create a Full Pipeline that we can use to feed the unprocessed information. In our case, it is the test data that we have prepared in the beginning.</p>
<p>To create the full pipeline, once again, you need to use Sciki-learn built-in method called <code>ColumnTransformer</code>. It is a relatively new feature. It is very efficient. We are also going to leverage the Pipelines we have created earlier. This is how we do this:</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.compose </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> ColumnTransformer</span></span>
<span class="line"></span>
<span class="line"><span style="color: #6A737D"># Make a dataset with nums only</span></span>
<span class="line"><span style="color: #E1E4E8">dataset_num </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> dataset.drop(</span><span style="color: #9ECBFF">"position"</span><span style="color: #E1E4E8">, </span><span style="color: #FFAB70">axis</span><span style="color: #F97583">=</span><span style="color: #79B8FF">1</span><span style="color: #E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">num_attribs </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> </span><span style="color: #79B8FF">list</span><span style="color: #E1E4E8">(dataset_num)</span></span>
<span class="line"><span style="color: #E1E4E8">cat_attribs </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> [</span><span style="color: #9ECBFF">"position"</span><span style="color: #E1E4E8">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">full_pipeline </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> ColumnTransformer([</span></span>
<span class="line"><span style="color: #E1E4E8">        (</span><span style="color: #9ECBFF">"num"</span><span style="color: #E1E4E8">, num_pipeline, num_attribs),</span></span>
<span class="line"><span style="color: #E1E4E8">        (</span><span style="color: #9ECBFF">"cat"</span><span style="color: #E1E4E8">, OneHotEncoder(), cat_attribs),</span></span>
<span class="line"><span style="color: #E1E4E8">    ])</span></span></code></pre>
<p>Please note: the third parameter for both functions within ColumnTransfomer are lists of columns that this function applies to.</p>
<p>Then we will perform a fit_transform on the dataset:</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #E1E4E8">dataset_prepared </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> full_pipeline.fit_transform(dataset)</span></span>
<span class="line"><span style="color: #E1E4E8">dataset_prepared.shape</span></span></code></pre>
<p><code>.shape</code> is here to check the dimensions of the final dataset. This is the result for me <code>(14516, 59)</code></p>
<h2 id="applying-the-machine-learning-algorithm">Applying the Machine Learning Algorithm</h2>
<p>There is a plethora of different Machine Learning Algorithms that was pre-built by Scikit learn. We are going to use the Random Forest Regressor. It is a robust algorithm.</p>
<p>I am not going to go into the details of how it works. There are some excellent resources out there that talk about this in detail.</p>
<p>If you followed along and did everything successfully, the following code looks extremely simple to you!</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.ensemble </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> RandomForestRegressor</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">forest_reg </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> RandomForestRegressor()</span></span>
<span class="line"><span style="color: #E1E4E8">forest_reg.fit(dataset_prepared, dataset_labels)</span></span></code></pre>
<p>That‚Äôs it. We now need to test the algorithm. One of the simplest ways to do this is to check the Root Mean Squared Error. The following code does not.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #E1E4E8">dataset_predictions </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> forest_reg.predict(dataset_prepared)</span></span>
<span class="line"><span style="color: #E1E4E8">forest_mse </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> mean_squared_error(dataset_labels, dataset_predictions)</span></span>
<span class="line"><span style="color: #E1E4E8">forest_rmse </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> np.sqrt(forest_mse)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #F97583">f</span><span style="color: #9ECBFF">'RMSE is $</span><span style="color: #79B8FF">{</span><span style="color: #E1E4E8">forest_rmse</span><span style="color: #F97583">:,.0f</span><span style="color: #79B8FF">}</span><span style="color: #9ECBFF">'</span></span></code></pre>
<p>I get <code>'RMSE is $374,525</code>. This means that, on average, the algorithm is only roughly off by $400k, which is not a lot compared to the actual values. We are talking millions here.</p>
<h3 id="saving-the-model">Saving the model</h3>
<p>Suppose we are happy with our model. Now the right thing to do would be to save it. The easiest way to do this is by using joblib function. It is easily accessible from sklearn.externals. This is how you save the model:</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">from</span><span style="color: #E1E4E8"> sklearn.externals </span><span style="color: #F97583">import</span><span style="color: #E1E4E8"> joblib</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">joblib.dump(forest_reg, </span><span style="color: #9ECBFF">"models/best_model.pkl"</span><span style="color: #E1E4E8">)</span></span></code></pre>
<p>Here the forest_reg is the model we want to save and the second parameter <code>"models/best_model.pkl"</code> is the path and the name of our new file.</p>
<p>You can check the directory to make sure everything saved correctly.</p>
<h2 id="evaluating-on-the-test-set">Evaluating on the test set</h2>
<p>Now that we have a working algorithm we want to use, it is time to finally test it on the test set to see if it works correctly.</p>
<p>We are going to take our test_set and feed it through the pipeline we created earlier. After that, we are going to feed it through the model we have trained. Excuse my ‚Äúfeed-through‚Äù language. This is the first thing that comes to mind.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #E1E4E8">final_model </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> best_model</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">X_test </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> strat_test_set.drop(</span><span style="color: #9ECBFF">"value"</span><span style="color: #E1E4E8">, </span><span style="color: #FFAB70">axis</span><span style="color: #F97583">=</span><span style="color: #79B8FF">1</span><span style="color: #E1E4E8">)</span></span>
<span class="line"><span style="color: #E1E4E8">y_test </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> strat_test_set[</span><span style="color: #9ECBFF">"value"</span><span style="color: #E1E4E8">].copy()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">X_test_prepared </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> full_pipeline.transform(X_test)</span></span></code></pre>
<p>The code above makes the final ‚Äúprepared file.‚Äù</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #E1E4E8">final_predictions </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> final_model.predict(X_test_prepared)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #E1E4E8">final_mse </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> mean_squared_error(y_test, final_predictions)</span></span>
<span class="line"><span style="color: #E1E4E8">final_rmse </span><span style="color: #F97583">=</span><span style="color: #E1E4E8"> np.sqrt(final_mse)</span></span></code></pre>
<p>Now we successfully ‚Äúfed‚Äù or dataset thought he model. The last thing to do is to evaluate the error.</p>
<pre is:raw="" class="astro-code github-dark" style="background-color: #24292e; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color: #F97583">f</span><span style="color: #9ECBFF">'RMSE is $</span><span style="color: #79B8FF">{</span><span style="color: #E1E4E8">forest_rmse</span><span style="color: #F97583">:,.0f</span><span style="color: #79B8FF">}</span><span style="color: #9ECBFF">'</span></span></code></pre>
<p><code>'RMSE is $359,161'</code></p>
<p>All right! The model performs better on the test set, rather than the training set. This is a little surprising to me. The difference is tiny, so no worries about underfitting.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>I can‚Äôt believe this is ‚Äúover.‚Äù</p>
<p>We have gone through the process of Data Analysis from Data cleaning to Building a Model. There are so many things I have left out, even things I did for this dataset. It is impossible to cover everything in one go. I hope this was at least a little tiny bit useful.</p>
<p>There are fantastic books written on these topics. The books that helped me write this post is ‚ÄòHands-on Machine Learning with Scikit-Learn, Keras &#x26; TensorFlow‚Äô by Aurelion Geron.</p>
<h2 id="final-final-thoughts">Final, final thoughts</h2>
<p>These are my first baby steps in the world of Machine Learning. These are the first baby steps in the world of Data Science blogging or any blogging for that matter. So, please do not be too harsh.</p>
<p>You know what, actually forget it. Please, be harsh. I don‚Äôt have too much free time, and I want to improve as quickly as possible. So, some constructive criticism would be great.</p>
<p>This post took me waaay to long to write. Also, I had big blocks of time in between those writing, so I am afraid of small inconsistencies.</p>
<p>In the future, I will try to break it up into a much smaller code block. I guess it was a little too ambitious to write a ‚Äúform start to finish‚Äù post as my first post. Well, I am happy I wrote. I am so glad it is now behind me, and I can move on with some other things.</p>
<p>I promise to try to be more consistent and more frequent with posts.</p></article><footer class="flex flex-col items-center justify-between w-full h-16 md:flex-row md:h-20 pin-b"><div class="flex flex-row"><a class="flex items-center pr-2 m-0 font-normal leading-tight text-center text-gray-600 border-0" href="/rss.xml">RSS</a></div><div class=""><a class="font-normal text-blue-700 border-0" href="https://xn--sr8hvo.ws/%E2%9E%B0%F0%9F%8D%8A%E2%8F%AD/previous">‚Üê</a>
An IndieWeb Webring üï∏üíç
<a class="font-normal text-blue-700 border-0" href="https://xn--sr8hvo.ws/%E2%9E%B0%F0%9F%8D%8A%E2%8F%AD/next">‚Üí</a></div></footer></footer></body></html>